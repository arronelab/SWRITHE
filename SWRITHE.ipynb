{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arronelab/SWRITHE/blob/main/SWRITHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jfuxDJDjtl6_"
      },
      "outputs": [],
      "source": [
        "#@title Clone Repo and Compile { display-mode: \"form\" }\n",
        "#@markdown Run this cell to clone the writhe calculator git repo.\n",
        "%%capture\n",
        "%cd /content/\n",
        "%shell rm -rf src\n",
        "!git clone --depth 1 https://github.com/arronelab/writheCalculator.git src\n",
        "%cd src/src/\n",
        "%shell sh makeFileAbs.sh\n",
        "%shell sh makeFileDI.sh\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pip installs and imports\n",
        "#@markdown Run this cell to install and import the requisite packages.\n",
        "%%capture\n",
        "!pip install biotite\n",
        "!pip install Bio\n",
        "!pip install PSIPREDauto\n",
        "from PSIPREDauto.functions import single_submit\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import os, re, shutil\n",
        "from tempfile import gettempdir\n",
        "import biotite\n",
        "import biotite.structure as struc\n",
        "import biotite.structure.io.mmtf as mmtf\n",
        "import biotite.sequence as seq\n",
        "import biotite.database.rcsb as rcsb\n",
        "from Bio.PDB import *\n",
        "from sklearn.cluster import DBSCAN\n",
        "from collections import defaultdict\n",
        "from scipy import interpolate"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wsNJIChfi_eT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions\n",
        "def get_chains_from_biotite(pdb_code):\n",
        "    # Fetch and load structure\n",
        "    file_name = rcsb.fetch(pdb_code.upper(), \"mmtf\", gettempdir())\n",
        "    mmtf_file = mmtf.MMTFFile.read(file_name)\n",
        "    array = mmtf.get_structure(mmtf_file, model=1)\n",
        "    array = array[struc.filter_amino_acids(array)]\n",
        "    return struc.get_chains(array)\n",
        "\n",
        "def convert(s):\n",
        "    new = \"\"\n",
        "    for x in s:\n",
        "        new+= x\n",
        "    return new\n",
        "\n",
        "def simple_ss_clean(fp):\n",
        "    for i in range(len(fp)-1):\n",
        "        if fp[i-1]==fp[i+1] and fp[i-1]!=fp[i]:\n",
        "            fp[i]=fp[i-1]\n",
        "    return convert(fp)\n",
        "\n",
        "def get_ss_from_biotite(pdb_code,chain):\n",
        "    d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
        "         'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
        "         'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
        "         'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
        "    # Dictionary to convert 'secStructList' codes to DSSP values\n",
        "    # https://github.com/rcsb/mmtf/blob/master/spec.md#secstructlist\n",
        "    sec_struct_codes = {0 : \"I\",\n",
        "                        1 : \"S\",\n",
        "                        2 : \"H\",\n",
        "                        3 : \"E\",\n",
        "                        4 : \"G\",\n",
        "                        5 : \"B\",\n",
        "                        6 : \"T\",\n",
        "                        7 : \"C\",\n",
        "                       -1 : \"C\"}\n",
        "    # Converter for the DSSP secondary structure elements\n",
        "    # to the classical ones\n",
        "    dssp_to_abc = {\"I\" : \"H\",\n",
        "                  \"S\" : \"-\",\n",
        "                  \"H\" : \"H\",\n",
        "                  \"E\" : \"S\",\n",
        "                  \"G\" : \"H\",\n",
        "                  \"B\" : \"S\",\n",
        "                  \"T\" : \"-\",\n",
        "                  \"C\" : \"-\"}\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch and load structure\n",
        "    file_name = rcsb.fetch(pdb_code.upper(), \"mmtf\", gettempdir())\n",
        "    mmtf_file = mmtf.MMTFFile.read(file_name)\n",
        "    array = mmtf.get_structure(mmtf_file, model=1)\n",
        "    array = array[struc.filter_amino_acids(array)]\n",
        "    array = array[array.chain_id==chain]\n",
        "    array = array[array.atom_name=='CA']\n",
        "    array = array[array.hetero==False]\n",
        "    array = array[np.array([i.res_name in list(d.keys()) for i in array])]\n",
        "    chain_id_per_res = array.chain_id[struc.get_residue_starts(array)]\n",
        "    sse = mmtf_file[\"secStructList\"]\n",
        "    sse = sse[:len(array)]\n",
        "    sse = np.array([sec_struct_codes[code] for code in sse],\n",
        "                  dtype=\"U1\")\n",
        "    sse = np.array([dssp_to_abc[e] for e in sse], dtype=\"U1\")\n",
        "    return get_sses(simple_ss_clean(sse))\n",
        "\n",
        "def get_backbone_from_biotite(pdb_code,chain):\n",
        "    d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
        "        'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
        "        'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
        "        'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
        "    # Fetch and load structure\n",
        "    file_name = rcsb.fetch(pdb_code.upper(), \"mmtf\", gettempdir())\n",
        "    mmtf_file = mmtf.MMTFFile.read(file_name)\n",
        "    array = mmtf.get_structure(mmtf_file, model=1)\n",
        "    array = array[struc.filter_amino_acids(array)]\n",
        "    array = array[array.chain_id==chain]\n",
        "    array = array[array.atom_name=='CA']\n",
        "    array = array[array.hetero==False]\n",
        "    array = array[np.array([i.res_name in list(d.keys()) for i in array])]\n",
        "    coords = [i.coord for i in array]\n",
        "    return coords\n",
        "\n",
        "def simplify_sec_struc(SS):\n",
        "    simplify_dict = {\n",
        "      'H': 'H',\n",
        "      'B': 'S',\n",
        "      'E': 'S',\n",
        "      'G': 'H',\n",
        "      'I': 'H',\n",
        "      'T': '-',\n",
        "      'S': '-',\n",
        "      '-': '-',\n",
        "      'C': '-'\n",
        "    }\n",
        "    simp_sec_struc = []\n",
        "    for i in SS:\n",
        "      simp_sec_struc.append(simplify_dict[i])\n",
        "    return simp_sec_struc\n",
        "\n",
        "def split(word):\n",
        "    return [char for char in word]\n",
        "\n",
        "def get_ss_from_fasta(fasta_file):\n",
        "    lines = []\n",
        "    with open(fasta_file,'r') as fin:\n",
        "        for line in fin:\n",
        "            lines+= [line.split()]\n",
        "    ss = lines[-1][0]\n",
        "    ss = split(ss)\n",
        "    simple_ss = simplify_sec_struc(split(ss))\n",
        "    return ''.join(simple_ss)\n",
        "\n",
        "def get_sses(ss):\n",
        "    sses = []\n",
        "    count = 1\n",
        "    i = 0\n",
        "    while i<len(ss)-1:\n",
        "        if ss[i+1] == ss[i]:\n",
        "            count += 1\n",
        "            i += 1\n",
        "        else:\n",
        "            sses.append([ss[i], count])\n",
        "            count = 1\n",
        "            i += 1\n",
        "    sses.append([ss[-1], count])\n",
        "    return sses\n",
        "\n",
        "def get_first_chain_fasta(xyz_file,fasta_file):\n",
        "    ca = np.genfromtxt(xyz_file)\n",
        "    lines = []\n",
        "    with open(fasta_file,'r') as fin:\n",
        "        for line in fin:\n",
        "            lines+= [line.split()]\n",
        "    return lines[1][0][:len(ca)]\n",
        "\n",
        "def overwrite_fasta_file(xyz_file,fasta_file):\n",
        "      lines=[]\n",
        "      with open(fasta_file,'r') as fin:\n",
        "          for line in fin:\n",
        "              lines+= [line.split()]\n",
        "      first_line = ' '.join(lines[0])\n",
        "      second_line = get_first_chain_fasta(xyz_file,fasta_file)\n",
        "      with open(fasta_file,'w') as fout:\n",
        "        fout.write(first_line)\n",
        "        fout.write('\\n')\n",
        "        fout.write(second_line)\n",
        "\n",
        "def running_mean(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "def set_axes_radius(ax, origin, radius):\n",
        "    ax.set_xlim3d([origin[0] - radius, origin[0] + radius])\n",
        "    ax.set_ylim3d([origin[1] - radius, origin[1] + radius])\n",
        "    ax.set_zlim3d([origin[2] - radius, origin[2] + radius])\n",
        "\n",
        "\n",
        "def set_axes_equal(ax, zoom=1.):\n",
        "    '''\n",
        "        Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
        "        cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
        "        ax.set_aspect(\"equal\") and ax.axis(\"equal\") not working for 3D.\n",
        "        input:\n",
        "          ax:   a matplotlib axis, e.g., as output from plt.gca().\n",
        "\n",
        "    '''\n",
        "    limits = np.array([\n",
        "        ax.get_xlim3d(),\n",
        "        ax.get_ylim3d(),\n",
        "        ax.get_zlim3d(),\n",
        "    ])\n",
        "\n",
        "    origin = np.mean(limits, axis=1)\n",
        "    radius = 0.5 * np.max(np.abs(limits[:, 1] - limits[:, 0])) / zoom\n",
        "    set_axes_radius(ax, origin, radius)\n",
        "\n",
        "def view_molecule(molecule):\n",
        "    mol = np.genfromtxt(molecule)\n",
        "    x_true = [i[0] for i in mol]\n",
        "    y_true = [i[1] for i in mol]\n",
        "    z_true = [i[2] for i in mol]\n",
        "    tck, u = interpolate.splprep([x_true,y_true,z_true], s=5)\n",
        "    u_fine = np.linspace(0,1,10*len(mol))\n",
        "    x_fine, y_fine, z_fine = interpolate.splev(u_fine, tck)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter3d(x=x_fine,\n",
        "                               y=y_fine,\n",
        "                               z=z_fine,\n",
        "                               marker=dict(size=1,\n",
        "                                           color='black'\n",
        "                                           ),\n",
        "                               line=dict(width=15,\n",
        "                                         color='rgba(0,0,0,0.75)')\n",
        "                               )\n",
        "    )\n",
        "    fig.add_trace(go.Scatter3d(x=x_fine,\n",
        "                               y=y_fine,\n",
        "                               z=z_fine,\n",
        "                               marker=dict(size=1,\n",
        "                                           color=[i*100/len(x_fine) for i in range(len(x_fine))],\n",
        "                                           colorscale='dense'\n",
        "                                           ),\n",
        "                               line=dict(width=10,\n",
        "                                         color=[i*100/len(x_fine) for i in range(len(x_fine))],\n",
        "                                         colorscale='dense'\n",
        "                                         ),\n",
        "                               )\n",
        "    )\n",
        "    colorbar_trace = go.Scatter3d(x=[None],\n",
        "                          y=[None], z=[None],\n",
        "                          mode='markers',\n",
        "                          marker=dict(\n",
        "                              colorscale='dense',\n",
        "                              showscale=True,\n",
        "                              cmin=-5,\n",
        "                              cmax=5,\n",
        "                              colorbar=dict(thickness=25, tickvals=[-5, 5], ticktext=['Start','End'], outlinewidth=0)\n",
        "                          ),\n",
        "                          hoverinfo='none'\n",
        "                        )\n",
        "    fig['layout']['showlegend'] = False\n",
        "    fig.add_trace(colorbar_trace)\n",
        "    fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='',\n",
        "        yaxis_title='',\n",
        "        zaxis_title='',\n",
        "        aspectratio = dict(x=1,y=1,z=1),\n",
        "        aspectmode = 'manual',\n",
        "        xaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        yaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        zaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),),\n",
        "    )\n",
        "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "    return fig.show()\n",
        "\n",
        "def get_all_edges(curve):\n",
        "    edges=[]\n",
        "    for i in range(1,len(curve)):\n",
        "        edges.append([curve[i-1],curve[i]])\n",
        "    return edges\n",
        "\n",
        "def split(word):\n",
        "    return [char for char in word]\n",
        "\n",
        "def get_sses(ss):\n",
        "    sses = []\n",
        "    count = 1\n",
        "    i = 0\n",
        "    while i<len(ss)-1:\n",
        "        if ss[i+1] == ss[i]:\n",
        "            count += 1\n",
        "            i += 1\n",
        "        else:\n",
        "            sses.append([ss[i], count])\n",
        "            count = 1\n",
        "            i += 1\n",
        "    sses.append([ss[-1], count])\n",
        "    return sses\n",
        "\n",
        "\n",
        "\n",
        "def intersect_line_triangle(q1,q2,p1,p2,p3):\n",
        "    def signed_tetra_volume(a,b,c,d):\n",
        "        return np.sign(np.dot(np.cross(b-a,c-a),d-a)/6.0)\n",
        "\n",
        "    s1 = signed_tetra_volume(q1,p1,p2,p3)\n",
        "    s2 = signed_tetra_volume(q2,p1,p2,p3)\n",
        "\n",
        "    if s1 != s2:\n",
        "        s3 = signed_tetra_volume(q1,q2,p1,p2)\n",
        "        s4 = signed_tetra_volume(q1,q2,p2,p3)\n",
        "        s5 = signed_tetra_volume(q1,q2,p3,p1)\n",
        "        if s3 == s4 and s4 == s5:\n",
        "            n = np.cross(p2-p1,p3-p1)\n",
        "            t = np.dot(p1-q1,n) / np.dot(q2-q1,n)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def skmt(pdb_code,chain):\n",
        "    mol = get_backbone_from_biotite(pdb_code,chain)\n",
        "    ss = get_ss_from_biotite(pdb_code,chain)\n",
        "    splitcurve = []\n",
        "    index = 0\n",
        "    for i in ss:\n",
        "        splitcurve.append(mol[index:index+i[1]])\n",
        "        index+=i[1]\n",
        "    newcurve = []\n",
        "    for i in range(len(splitcurve)):\n",
        "        for j in range(len(splitcurve[i])):\n",
        "            newcurve.append(splitcurve[i][j])\n",
        "    for subsec in range(len(splitcurve)):\n",
        "        if len(splitcurve[subsec])>2:\n",
        "            checks = []\n",
        "            for idx in range(1,len(splitcurve[subsec])-1):\n",
        "                p1 = 2*splitcurve[subsec][0]-splitcurve[subsec][1]\n",
        "                p2 = splitcurve[subsec][idx]\n",
        "                p3 = 2*splitcurve[subsec][-1]-splitcurve[subsec][-2]\n",
        "                for edge in get_all_edges(newcurve):\n",
        "                    q0 = edge[0]\n",
        "                    q1 = edge[1]\n",
        "                    checks.append(intersect_line_triangle(q0,q1,p1,p2,p3))\n",
        "            if not any(checks):\n",
        "                splitcurve[subsec] = [splitcurve[subsec][0]]\n",
        "                newcurve = []\n",
        "                for l in range(len(splitcurve)):\n",
        "                    for m in range(len(splitcurve[l])):\n",
        "                        newcurve.append(splitcurve[l][m])\n",
        "            else:\n",
        "                idx=2\n",
        "                while idx<len(splitcurve[subsec]):\n",
        "                    newcurve = []\n",
        "                    for i in range(len(splitcurve)):\n",
        "                        for j in range(len(splitcurve[i])):\n",
        "                            newcurve.append(splitcurve[i][j])\n",
        "                    p1 = splitcurve[subsec][idx-2]\n",
        "                    p2 = splitcurve[subsec][idx-1]\n",
        "                    p3 = splitcurve[subsec][idx]\n",
        "                    checks = []\n",
        "                    for edge in get_all_edges(newcurve):\n",
        "                        q0 = edge[0]\n",
        "                        q1 = edge[1]\n",
        "                        checks.append(intersect_line_triangle(q0,q1,p1,p2,p3))\n",
        "                    if not any(checks):\n",
        "                        splitcurve[subsec] = np.delete(splitcurve[subsec],idx-1,axis=0)\n",
        "                        idx=2\n",
        "                    else:\n",
        "                        idx+=1\n",
        "        else:\n",
        "            splitcurve[subsec] = [splitcurve[subsec][0]]\n",
        "            newcurve = []\n",
        "            for l in range(len(splitcurve)):\n",
        "                for m in range(len(splitcurve[l])):\n",
        "                    newcurve.append(splitcurve[l][m])\n",
        "    newcurve = []\n",
        "    for i in range(len(splitcurve)):\n",
        "        for j in range(len(splitcurve[i])):\n",
        "          newcurve.append(splitcurve[i][j])\n",
        "    if not np.array_equal(newcurve[-1],mol[-1]):\n",
        "        newcurve.append(mol[-1])\n",
        "    return newcurve\n",
        "\n",
        "def write_curve_to_file(curve,outfile_name):\n",
        "    with open(outfile_name,'w+') as f:\n",
        "        for i in range(len(curve)-1):\n",
        "            string = ' '.join(map(str,curve[i]))\n",
        "            f.write(string)\n",
        "            f.write('\\n')\n",
        "        f.write(' '.join(map(str,curve[-1])))\n",
        "        f.close()\n",
        "\n",
        "def view_molecule_subset(molecule,start,end):\n",
        "    mol = np.genfromtxt(molecule)\n",
        "    xs = mol[:,0][start:end]\n",
        "    ys = mol[:,1][start:end]\n",
        "    zs = mol[:,2][start:end]\n",
        "    fig = go.Figure(data=go.Scatter3d(\n",
        "        x=xs, y=ys, z=zs,opacity=0.9,\n",
        "        marker=dict(\n",
        "            size=1,\n",
        "            color=[i*100/len(xs) for i in range(len(xs))],\n",
        "            colorscale='Rainbow'\n",
        "        ),\n",
        "        line=dict(\n",
        "            width=10,\n",
        "            color=[i*100/len(xs) for i in range(len(xs))],\n",
        "            colorscale='Rainbow'\n",
        "        ),))\n",
        "    colorbar_trace = go.Scatter3d(x=[None],\n",
        "                          y=[None], z=[None],\n",
        "                          mode='markers',\n",
        "                          marker=dict(\n",
        "                              colorscale='Rainbow',\n",
        "                              showscale=True,\n",
        "                              cmin=-5,\n",
        "                              cmax=5,\n",
        "                              colorbar=dict(thickness=25, tickvals=[-5, 5], ticktext=['Start','End'], outlinewidth=0)\n",
        "                          ),\n",
        "                          hoverinfo='none'\n",
        "                        )\n",
        "    fig['layout']['showlegend'] = False\n",
        "    fig.add_trace(colorbar_trace)\n",
        "    fig.update_layout(width=1250,height=1000)\n",
        "    fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='',\n",
        "        yaxis_title='',\n",
        "        zaxis_title='',\n",
        "        aspectratio = dict( x=1, y=1, z=1 ),\n",
        "        aspectmode = 'manual',\n",
        "        xaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        yaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        zaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),),\n",
        "    )\n",
        "    return fig.show()\n",
        "\n",
        "def find_helical_sections(writhe_file):\n",
        "    DI = np.genfromtxt(writhe_file)[:len(np.genfromtxt(writhe_file[:-12]+'.xyz'))-4]\n",
        "    x1 = DI[:,0]\n",
        "    x2 = DI[:,1]\n",
        "    x=x2-x1+1\n",
        "    y = DI[:,2]\n",
        "    hels = []\n",
        "    for i in range(len(x)-7):\n",
        "        for j in range(i+7,len(x)):\n",
        "            if abs((y[j]-y[i])/(x[j]-x[i])) > 0.1:\n",
        "                hels.append([x[i],x[j],y[j]-y[i]])\n",
        "    ranges = [[i[0],i[1]] for i in hels]\n",
        "    sizes = []\n",
        "    for i in ranges:\n",
        "        sizes.append(i[1]-i[0])\n",
        "    largest=[]\n",
        "    for i in range(len(sizes)):\n",
        "        if sizes[i] == max(sizes):\n",
        "            largest.append(i)\n",
        "    res=[]\n",
        "    for i in largest:\n",
        "      res.append(ranges[i])\n",
        "    return res\n",
        "\n",
        "def view_molecule_helical(molecule,DI,res):\n",
        "    colors = px.colors.sequential.dense\n",
        "    colspace = np.linspace(0,10,len(res)+2)[1:-1]\n",
        "    mol = np.genfromtxt(molecule)\n",
        "    x = mol[:,0]\n",
        "    y = mol[:,1]\n",
        "    z = mol[:,2]\n",
        "    cols = ['black' for i in range(len(x))]\n",
        "    for i in range(len(res)):\n",
        "        stindex = np.where(DI[:,1] == res[i][0])[0][0]\n",
        "        endex = np.where(DI[:,1]==res[i][1])[0][0]\n",
        "        for j in range(stindex,endex):\n",
        "          cols[j] = colors[int(colspace[i])]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=x, y=y, z=z,\n",
        "        marker=dict(\n",
        "            size=1,\n",
        "            color=cols\n",
        "        ),\n",
        "        line=dict(\n",
        "            width=15,\n",
        "            color=cols\n",
        "        ),))\n",
        "    fig['layout']['showlegend'] = False\n",
        "    fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='',\n",
        "        yaxis_title='',\n",
        "        zaxis_title='',\n",
        "        aspectratio = dict( x=1, y=1, z=1 ),\n",
        "        aspectmode = 'manual',\n",
        "        xaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        yaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        zaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),),\n",
        "    )\n",
        "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "    return fig.show()\n",
        "\n",
        "def view_molecule_roadie(molecule,DI,res):\n",
        "    colors = px.colors.sequential.dense\n",
        "    colspace = np.linspace(0,10,len(res)+2)[1:-1]\n",
        "    mol = np.genfromtxt(molecule)\n",
        "    x = mol[:,0]\n",
        "    y = mol[:,1]\n",
        "    z = mol[:,2]\n",
        "    cols = ['black' for i in range(len(x))]\n",
        "    for i in range(len(res)):\n",
        "        stindex = np.where(DI[:,1] == res[i][0]+4)[0][0]\n",
        "        endex = np.where(DI[:,1]==res[i][1])[0][0]\n",
        "        for j in range(stindex,endex):\n",
        "          cols[j] = colors[int(colspace[i])]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=x, y=y, z=z,\n",
        "        marker=dict(\n",
        "            size=1,\n",
        "            color=cols\n",
        "        ),\n",
        "        line=dict(\n",
        "            width=15,\n",
        "            color=cols\n",
        "        ),))\n",
        "    fig['layout']['showlegend'] = False\n",
        "    fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='',\n",
        "        yaxis_title='',\n",
        "        zaxis_title='',\n",
        "        aspectratio = dict( x=1, y=1, z=1 ),\n",
        "        aspectmode = 'manual',\n",
        "        xaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        yaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),\n",
        "        zaxis = dict(\n",
        "            gridcolor=\"white\",\n",
        "            showbackground=False,\n",
        "            zerolinecolor=\"white\",\n",
        "            nticks=0,\n",
        "            showticklabels=False),),\n",
        "    )\n",
        "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "    return fig.show()\n",
        "\n",
        "\n",
        "\n",
        "def calculate_writhe(curveFile):\n",
        "    #open that file into numpy array\n",
        "    coords = np.loadtxt(curveFile)\n",
        "    #make a list of subsets of this curve\n",
        "    size=int(np.size(coords)/3)\n",
        "    # we need at least 5 points for a reasonable writhe make\n",
        "    workingDirectory=os.getcwd()\n",
        "    os.mkdir(workingDirectory+\"/tmp\")\n",
        "    f3 = open(curveFile[:-4]+'_writhes.dat', 'w+')\n",
        "    for i in range(0,size-4):\n",
        "        for j in range(i+5,size+1):\n",
        "            subsets=coords[i:j]\n",
        "            # write it to file\n",
        "            subfile=(\"tmp/subcurve{:d}.dat\".format(i-4))\n",
        "            np.savetxt(subfile,subsets[:])\n",
        "            fullloc3 =\"/content/src/src/DIwr \"+subfile\n",
        "            f3.write(str(i+1)+\" \" +str(j)+\" \" + os.popen(fullloc3).read()+\"\\n\")\n",
        "            os.remove(subfile)\n",
        "    shutil.rmtree(workingDirectory+\"/tmp\")\n",
        "    f3.close()\n",
        "\n",
        "def calculate_abs_writhe(curveFile):\n",
        "    #open that file into numpy array\n",
        "    coords = np.loadtxt(curveFile)\n",
        "    #make a list of subsets of this curve\n",
        "    size=int(np.size(coords)/3)\n",
        "    # we need at least 5 points for a reasonable writhe make\n",
        "    workingDirectory=os.getcwd()\n",
        "    os.mkdir(workingDirectory+\"/tmp\")\n",
        "    f3 = open(curveFile[:-4]+'_abswrithes.dat', 'w+')\n",
        "    for i in range(0,size-4):\n",
        "        for j in range(i+5,size+1):\n",
        "            subsets=coords[i:j]\n",
        "            # write it to file\n",
        "            subfile=(\"tmp/subcurve{:d}.dat\".format(i-4))\n",
        "            np.savetxt(subfile,subsets[:])\n",
        "            fullloc3 =\"/content/src/src/AbsDI \"+subfile\n",
        "            f3.write(str(i+1)+\" \" +str(j)+\" \" + os.popen(fullloc3).read()+\"\\n\")\n",
        "            os.remove(subfile)\n",
        "    shutil.rmtree(workingDirectory+\"/tmp\")\n",
        "    f3.close()\n",
        "\n",
        "def pdb_to_fasta(pdb_file_loc,chain):\n",
        "    aa3to1={\n",
        "   'ALA':'A', 'VAL':'V', 'PHE':'F', 'PRO':'P', 'MET':'M',\n",
        "   'ILE':'I', 'LEU':'L', 'ASP':'D', 'GLU':'E', 'LYS':'K',\n",
        "   'ARG':'R', 'SER':'S', 'THR':'T', 'TYR':'Y', 'HIS':'H',\n",
        "   'CYS':'C', 'ASN':'N', 'GLN':'Q', 'TRP':'W', 'GLY':'G',\n",
        "   'MSE':'M', 'HID': 'H', 'HIP': 'H'\n",
        "    }\n",
        "    ca_pattern=re.compile(\"^ATOM\\s{2,6}\\d{1,5}\\s{2}CA\\s[\\sA]([A-Z]{3})\\s([\\s\\w])|^HETATM\\s{0,4}\\d{1,5}\\s{2}CA\\s[\\sA](MSE)\\s([\\s\\w])\")\n",
        "    filename=os.path.basename(pdb_file_loc).split('.')[0]\n",
        "    chain_dict=dict()\n",
        "    chain_list=[]\n",
        "    fp=open(pdb_file_loc,'r')\n",
        "    for line in fp.read().splitlines():\n",
        "        if line.startswith(\"ENDMDL\"):\n",
        "            break\n",
        "        match_list=ca_pattern.findall(line)\n",
        "        if match_list:\n",
        "            resn=match_list[0][0]+match_list[0][2]\n",
        "            chain=match_list[0][1]+match_list[0][3]\n",
        "            if chain in chain_dict:\n",
        "                chain_dict[chain]+=aa3to1[resn]\n",
        "            else:\n",
        "                chain_dict[chain]=aa3to1[resn]\n",
        "                chain_list.append(chain)\n",
        "    fp.close()\n",
        "    with open(pdb_file_loc[:-4]+'.fasta','w+') as fout:\n",
        "      fout.write(chain_dict[chain])\n",
        "\n",
        "def get_ss_fp_psipred(fasta_file_loc):\n",
        "  dssp_to_simp = {\"I\" : \"H\",\n",
        "                 \"S\" : \"-\",\n",
        "                 \"H\" : \"H\",\n",
        "                 \"E\" : \"S\",\n",
        "                 \"G\" : \"H\",\n",
        "                 \"B\" : \"S\",\n",
        "                 \"T\" : \"-\",\n",
        "                 \"C\" : \"-\"\n",
        "                 }\n",
        "  lines = []\n",
        "  with open(fasta_file_loc+' output/'+os.path.splitext(os.path.basename(fasta_file_loc))[0]+'.ss','r') as fin:\n",
        "    for line in fin:\n",
        "      lines.append(line.split())\n",
        "  ss = [dssp_to_simp[i[2]] for i in lines]\n",
        "  return get_sses(simple_ss_clean(ss))\n",
        "\n",
        "\n",
        "def skmt_upload(pdb_file_loc,chain):\n",
        "    mol = np.genfromtxt(pdb_file_loc[:-4]+'.xyz')\n",
        "    ss = get_ss_fp_psipred(pdb_file_loc[:-4]+'.fasta')\n",
        "    splitcurve = []\n",
        "    index = 0\n",
        "    for i in ss:\n",
        "        splitcurve.append(mol[index:index+i[1]])\n",
        "        index+=i[1]\n",
        "    newcurve = []\n",
        "    for i in range(len(splitcurve)):\n",
        "        for j in range(len(splitcurve[i])):\n",
        "            newcurve.append(splitcurve[i][j])\n",
        "    for subsec in range(len(splitcurve)):\n",
        "        if len(splitcurve[subsec])>2:\n",
        "            checks = []\n",
        "            for idx in range(1,len(splitcurve[subsec])-1):\n",
        "                p1 = splitcurve[subsec][0]\n",
        "                p2 = splitcurve[subsec][idx]\n",
        "                p3 = splitcurve[subsec][-1]\n",
        "                for edge in get_all_edges(newcurve):\n",
        "                    q0 = edge[0]\n",
        "                    q1 = edge[1]\n",
        "                    checks.append(intersect_line_triangle(q0,q1,p1,p2,p3))\n",
        "            if not any(checks):\n",
        "                splitcurve[subsec] = [splitcurve[subsec][0]]\n",
        "                newcurve = []\n",
        "                for l in range(len(splitcurve)):\n",
        "                    for m in range(len(splitcurve[l])):\n",
        "                        newcurve.append(splitcurve[l][m])\n",
        "            else:\n",
        "                idx=2\n",
        "                while idx<len(splitcurve[subsec]):\n",
        "                    newcurve = []\n",
        "                    for i in range(len(splitcurve)):\n",
        "                        for j in range(len(splitcurve[i])):\n",
        "                            newcurve.append(splitcurve[i][j])\n",
        "                    p1 = splitcurve[subsec][idx-2]\n",
        "                    p2 = splitcurve[subsec][idx-1]\n",
        "                    p3 = splitcurve[subsec][idx]\n",
        "                    checks = []\n",
        "                    for edge in get_all_edges(newcurve):\n",
        "                        q0 = edge[0]\n",
        "                        q1 = edge[1]\n",
        "                        checks.append(intersect_line_triangle(q0,q1,p1,p2,p3))\n",
        "                    if not any(checks):\n",
        "                        splitcurve[subsec] = np.delete(splitcurve[subsec],idx-1,axis=0)\n",
        "                        idx=2\n",
        "                    else:\n",
        "                        idx+=1\n",
        "        else:\n",
        "            splitcurve[subsec] = [splitcurve[subsec][0]]\n",
        "            newcurve = []\n",
        "            for l in range(len(splitcurve)):\n",
        "                for m in range(len(splitcurve[l])):\n",
        "                    newcurve.append(splitcurve[l][m])\n",
        "    newcurve = []\n",
        "    for i in range(len(splitcurve)):\n",
        "        for j in range(len(splitcurve[i])):\n",
        "          newcurve.append(splitcurve[i][j])\n",
        "    if not np.array_equal(newcurve[-1],mol[-1]):\n",
        "        newcurve.append(mol[-1])\n",
        "    return newcurve\n",
        "\n",
        "def sim(wr1,wr2,i,j,k,l):\n",
        "    assert j-i == l-k\n",
        "    assert j-i>=4\n",
        "    sum_elements = []\n",
        "    for idx in range(len(wr1)):\n",
        "      if wr1[idx][0]==i:\n",
        "        idx1=idx\n",
        "        break\n",
        "    for idx in range(len(wr2)):\n",
        "      if wr2[idx][0]==k:\n",
        "        idx2=idx\n",
        "        break\n",
        "    for m in range(0,j-i-3):\n",
        "      sum_elements.append(abs(wr1[idx1+m][2]-wr2[idx2+m][2])/(abs(wr1[idx1+m][2])+abs(wr2[idx2+m][2])))\n",
        "    return 1-sum(sum_elements)/(j-i)\n",
        "\n",
        "\n",
        "def find_sim_sections(wrfile1,wrfile2):\n",
        "    wr1 = np.genfromtxt(wrfile1)\n",
        "    wr2 = np.genfromtxt(wrfile2)\n",
        "    sim_sections=[]\n",
        "    lenwr1 = int(wr1[-1][1])\n",
        "    lenwr2 = int(wr2[-1][1])\n",
        "    sim_scores = []\n",
        "    for i in range(1,lenwr1-7):\n",
        "      for j in range(i+8,lenwr1+1):\n",
        "        for k in range(1,lenwr2-7):\n",
        "          for l in range(k+9,lenwr2+1):\n",
        "            if j-i == l-k:\n",
        "              s = sim(wr1,wr2,i,j,k,l)\n",
        "              if s>0.85:\n",
        "                sim_sections.append([i,j,k,l,s])\n",
        "    return sim_sections\n",
        "\n",
        "def find_longest_sim_sections(wrfile1,wrfile2):\n",
        "    sim_sections = find_sim_sections(wrfile1,wrfile2)\n",
        "    sim_lengths=[]\n",
        "    for i in sim_sections:\n",
        "      sim_lengths.append(i[1]-i[0])\n",
        "    max_sim_length = max(sim_lengths)\n",
        "    longest_sim_sections=[]\n",
        "    for i in sim_sections:\n",
        "      if i[1]-i[0] == max_sim_length:\n",
        "        longest_sim_sections.append(i)\n",
        "    max_sim_score = max([i[-1] for i in longest_sim_sections])\n",
        "    idx = np.where([i[-1] for i in longest_sim_sections]==max_sim_score)[0][0]\n",
        "    return longest_sim_sections[idx]\n",
        "\n",
        "def plot_longest_sim_sections(wrfile1,wrfile2):\n",
        "    sim = find_longest_sim_sections(wrfile1,wrfile2)\n",
        "    wr1 = np.genfromtxt(wrfile1)\n",
        "    wr2 = np.genfromtxt(wrfile2)\n",
        "    x1 = wr1[:int(wr1[-1][1]-4)][:,1]\n",
        "    y1 = wr1[:int(wr1[-1][1]-4)][:,2]\n",
        "    x2 = wr2[:int(wr2[-1][1]-4)][:,1]\n",
        "    y2 = wr2[:int(wr2[-1][1]-4)][:,2]\n",
        "    fig=go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=x1,\n",
        "                             y=y1,\n",
        "                             name=wrfile1.split('_')[1],\n",
        "                             legendgroup=wrfile1.split('_')[1],\n",
        "                             mode='lines',\n",
        "                             marker=dict(color='firebrick',size=10),\n",
        "                             line=dict(width=5)))\n",
        "    if sim[0]<=x1[0]:\n",
        "      fig.add_trace(go.Scatter(x=x1[:np.where(x1==sim[1])[0][0]],\n",
        "                               y=y1[:np.where(x1==sim[1])[0][0]],\n",
        "                               name=wrfile1.split('_')[1],\n",
        "                               legendgroup=wrfile1.split('_')[1],\n",
        "                               showlegend=False,\n",
        "                               mode='lines',\n",
        "                               marker=dict(color='black',size=10),\n",
        "                               line=dict(width=5)))\n",
        "    else:\n",
        "      fig.add_trace(go.Scatter(x=x1[np.where(x1==sim[0])[0][0]:np.where(x1==sim[1])[0][0]],\n",
        "                               y=y1[np.where(x1==sim[0])[0][0]:np.where(x1==sim[1])[0][0]],\n",
        "                               name=wrfile1.split('_')[1],\n",
        "                               legendgroup=wrfile1.split('_')[1],\n",
        "                               showlegend=False,\n",
        "                               mode='lines',\n",
        "                               marker=dict(color='black',size=10),\n",
        "                               line=dict(width=5)))\n",
        "    fig.add_trace(go.Scatter(x=x2,\n",
        "                             y=y2,\n",
        "                             name=wrfile2.split('_')[1],\n",
        "                             legendgroup=wrfile2.split('_')[1],\n",
        "                             mode='lines',\n",
        "                             marker=dict(color='royalblue',size=10),\n",
        "                             line=dict(width=5)))\n",
        "    if sim[2]<=x2[0]:\n",
        "      fig.add_trace(go.Scatter(x=x2[:np.where(x2==sim[3])[0][0]],\n",
        "                               y=y2[:np.where(x2==sim[3])[0][0]],\n",
        "                               name=wrfile2.split('_')[1],\n",
        "                               legendgroup=wrfile2.split('_')[1],\n",
        "                               showlegend=False,\n",
        "                               mode='lines',\n",
        "                               marker=dict(color='black',size=10),\n",
        "                               line=dict(width=5)))\n",
        "    else:\n",
        "      fig.add_trace(go.Scatter(x=x2[np.where(x2==sim[2])[0][0]:np.where(x2==sim[3])[0][0]],\n",
        "                               y=y2[np.where(x2==sim[2])[0][0]:np.where(x2==sim[3])[0][0]],\n",
        "                               name=wrfile2.split('_')[1],\n",
        "                               legendgroup=wrfile2.split('_')[1],\n",
        "                               showlegend=False,\n",
        "                               mode='lines',\n",
        "                               marker=dict(color='black',size=10),\n",
        "                               line=dict(width=5)))\n",
        "    fig.update_layout(autosize=False,\n",
        "                      width=1000,\n",
        "                      height=0.75*1000)\n",
        "    fig.update_layout(font_family=\"Tenorite\",\n",
        "                      font_color=\"black\",\n",
        "                      title_font_family=\"Tenorite\",\n",
        "                      title_font_color=\"black\",\n",
        "                      legend_title_font_color=\"black\",\n",
        "                      xaxis_title=\"Subsection Length\",\n",
        "                      yaxis_title=\"Writhe\",\n",
        "                      font=dict(size=16)\n",
        "    )\n",
        "    fig.update_layout(template='simple_white')\n",
        "    fig.show()\n",
        "\n",
        "def measure_roadieness(wr_list_in):\n",
        "    wr_list_whole = [item for item in wr_list_in if item[1] > item[0]]\n",
        "    length = len(wr_list_whole)\n",
        "    result = []\n",
        "    for i in range(2, length):\n",
        "        wr_list = wr_list_whole[:i]\n",
        "        if len(wr_list) > 1:\n",
        "            wr_list = [item[2] for item in wr_list]\n",
        "            max_val = max(map(abs, wr_list))\n",
        "            end_diff = wr_list[-1] - wr_list[0]\n",
        "            result.append([wr_list_whole[i][0], wr_list_whole[i][1], max_val, end_diff])\n",
        "        else:\n",
        "            result.append([0, 0, 0.0, 0.0])\n",
        "    return result\n",
        "\n",
        "def retrieve_clusters(clustered_list):\n",
        "  no_noise = [i for i in clustered_list if i[1]!=-1]\n",
        "  res = defaultdict(list)\n",
        "  for v, k in no_noise: res[k].append(v)\n",
        "  returns = []\n",
        "  for key in res.keys():\n",
        "    returns.append(res[key][-1])\n",
        "  max_length = max([i[1]-i[0] for i in returns])\n",
        "  return [i for i in returns if i[1]-i[0]==max_length]\n",
        "\n",
        "def find_roadie_sections(fp):\n",
        "    rtests = measure_roadieness(np.genfromtxt(fp))\n",
        "    pos = [i for i, item in enumerate(rtests) if item[2] > 0.95 and abs(item[3]) < 0.05]\n",
        "    if len(pos) > 0:\n",
        "        potential_secs = [rtests[i] for i in pos]\n",
        "        uppers = list(set([item[1] for item in potential_secs]))\n",
        "        bound_pairs = []\n",
        "        for upper in uppers:\n",
        "            max_lower = max([item[0] for item in potential_secs if item[1] == upper])\n",
        "            bound_pairs.append([max_lower, upper])\n",
        "        if len(bound_pairs) > 1:\n",
        "            clus = [cluster for cluster in bound_pairs if cluster[1] - cluster[0] > 4]\n",
        "            clustering = DBSCAN(eps=3, min_samples=1).fit_predict(clus)\n",
        "            clustered = zip(clus,clustering)\n",
        "            return retrieve_clusters(list(clustered))\n",
        "        else:\n",
        "            return []\n",
        "    else:\n",
        "        return []"
      ],
      "metadata": {
        "id": "SYF-sV_ZjmaK",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ANvfq3XwwH1s"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Download PDB File and FASTA\n",
        "#@markdown Leave chain_id blank if unsure, this will take the first chain in the PDB file.\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "chain_id = \"\" #@param {type:\"string\"}\n",
        "if chain_id == \"\":\n",
        "    chain_id = get_chains_from_biotite(pdb_code)[0]\n",
        "if not os.path.exists('/content/'+pdb_code.lower()):\n",
        "    os.mkdir('/content/'+pdb_code.lower())\n",
        "urllib.request.urlretrieve('http://files.rcsb.org/download/'+pdb_code.lower()+'.pdb', '/content/'+pdb_code.lower()+'/'+pdb_code.lower()+'.pdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Er4OhsEriDhL"
      },
      "outputs": [],
      "source": [
        "#@title Extract backbone\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "chain_id = \"\" #@param {type:\"string\"}\n",
        "write_curve_to_file(get_backbone_from_biotite(pdb_code,chain_id),'/content/'+pdb_code.lower()+'/'+pdb_code.lower()+'.xyz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XDkLnZIFnn_r"
      },
      "outputs": [],
      "source": [
        "#@title Smooth Backbone using the SKMT method\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "chain_id = \"\" #@param {type:\"string\"}\n",
        "write_curve_to_file(skmt(pdb_code.lower(),chain_id),'/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU1dASZq9_fW"
      },
      "outputs": [],
      "source": [
        "#@title Calculate Writhe Profile of Smoothed Backbone (Recommended)\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "curveFile='/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'.xyz'\n",
        "calculate_writhe(curveFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rIT-Nl_AnDYb"
      },
      "outputs": [],
      "source": [
        "#@title Calculate acn Profile of Smoothed Backbone (Recommended)\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "curveFile='/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'.xyz'\n",
        "calculate_abs_writhe(curveFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkNS18Wo7GZD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plot Writhe Profile\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "colors = px.colors.sequential.dense\n",
        "highlight_helical_subsections = False #@param {type:\"boolean\"}\n",
        "highlight_roadie_subsections = False #@param {type:\"boolean\"}\n",
        "DI = np.genfromtxt('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')[:len(np.genfromtxt('/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz'))-4]\n",
        "if highlight_helical_subsections:\n",
        "    try:\n",
        "        res1 = find_helical_sections('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')\n",
        "        colspace = np.linspace(0,10,len(res1)+2)[1:-1]\n",
        "    except:\n",
        "        print('No helical subsections')\n",
        "        highlight_helical_subsections=False\n",
        "if highlight_roadie_subsections:\n",
        "    try:\n",
        "        res2 = find_roadie_sections('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')\n",
        "        colspace = np.linspace(0,10,len(res2)+2)[1:-1]\n",
        "    except:\n",
        "        print('No roadie subsections')\n",
        "        highlight_helical_subsections=False\n",
        "x1 = DI[:,0]\n",
        "x2 = DI[:,1]\n",
        "x = x2-x1+1\n",
        "y = DI[:,2]\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=x,y=y,mode='lines',name=pdb_code.upper(),\n",
        "                         marker=dict(color='black',size=10),\n",
        "                         line=dict(width=5)))\n",
        "if highlight_helical_subsections:\n",
        "    for i in range(len(res1)):\n",
        "        stindex = np.where(x == res1[i][0])[0][0]\n",
        "        endex = np.where(x==res1[i][1])[0][0]\n",
        "        fig.add_trace(go.Scatter(x=x[stindex:endex],y=y[stindex:endex],\n",
        "                                  mode='lines',\n",
        "                                  name='Helical Subsection '+str(i+1),\n",
        "                                  showlegend=True,\n",
        "                                  marker=dict(color=colors[int(colspace[i])],\n",
        "                                              size=10),\n",
        "                                  line=dict(width=7.5)\n",
        "                                  )\n",
        "        )\n",
        "if highlight_roadie_subsections:\n",
        "    for i in range(len(res2)):\n",
        "        stindex = np.where(x == res2[i][0]+4)[0][0]\n",
        "        endex = np.where(x==res2[i][1])[0][0]\n",
        "        fig.add_trace(go.Scatter(x=x[stindex:endex],y=y[stindex:endex],\n",
        "                                  mode='lines',\n",
        "                                  name='Roadie Subsection '+str(i+1),\n",
        "                                  showlegend=True,\n",
        "                                  marker=dict(color=colors[int(colspace[i])],\n",
        "                                              size=10),\n",
        "                                  line=dict(width=7.5)\n",
        "                                  )\n",
        "        )\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=0.75*1000)\n",
        "fig.update_layout(\n",
        "    font_family=\"Tenorite\",\n",
        "    font_color=\"black\",\n",
        "    title_font_family=\"Tenorite\",\n",
        "    title_font_color=\"black\",\n",
        "    legend_title_font_color=\"black\",\n",
        "    xaxis_title=\"Subsection Length\",\n",
        "    yaxis_title=\"Writhe\",\n",
        "    font=dict(size=16)\n",
        ")\n",
        "fig.update_layout(template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IZvWsEJ7nKIg"
      },
      "outputs": [],
      "source": [
        "#@title Plot acn Profile\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "colors = px.colors.sequential.dense\n",
        "DI = np.genfromtxt('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_abswrithes.dat')\n",
        "x = DI[:,0]\n",
        "y = DI[:,1]\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=x,y=y,mode='lines',name=pdb_code.upper(),\n",
        "                         marker=dict(color='black',size=10),\n",
        "                         line=dict(width=5)))\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=0.75*1000)\n",
        "fig.update_layout(\n",
        "    font_family=\"Tenorite\",\n",
        "    font_color=\"black\",\n",
        "    title_font_family=\"Tenorite\",\n",
        "    title_font_color=\"black\",\n",
        "    legend_title_font_color=\"black\",\n",
        "    xaxis_title=\"Subsection Length\",\n",
        "    yaxis_title=\"acn\",\n",
        "    font=dict(size=16)\n",
        ")\n",
        "fig.update_layout(template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o-zONvL2BnU9"
      },
      "outputs": [],
      "source": [
        "#@title View Smoothed Molecule\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "highlight_helical_subsections = False #@param {type:\"boolean\"}\n",
        "highlight_roadie_subsections = False #@param {type:\"boolean\"}\n",
        "if highlight_helical_subsections:\n",
        "    DI = np.genfromtxt('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')[:len(np.genfromtxt('/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz'))-4]\n",
        "    res = find_helical_sections('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')\n",
        "    view_molecule_helical('/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz',DI,res)\n",
        "if highlight_roadie_subsections:\n",
        "    DI = np.genfromtxt('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')[:len(np.genfromtxt('/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz'))-4]\n",
        "    res = find_roadie_sections('/content/'+pdb_code.lower()+'/'+'smooth_'+pdb_code.lower()+'_writhes.dat')\n",
        "    view_molecule_roadie('/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz',DI,res)\n",
        "else:\n",
        "    view_molecule('/content/'+pdb_code.lower()+'/smooth_'+pdb_code.lower()+'.xyz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nZc8aJIa5agX"
      },
      "outputs": [],
      "source": [
        "#@title View Molecule\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "view_molecule('/content/'+pdb_code.lower()+'/'+pdb_code.lower()+'.xyz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzRSLLkDysmD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Compare writhe profiles using Smax\n",
        "#@markdown Make sure you've ran the above cells to process each PDB file and compute its writhe profile before running this one.\n",
        "pdb_code1 = \"\" #@param {type:\"string\"}\n",
        "pdb_code2 = \"\" #@param {type:\"string\"}\n",
        "plot_longest_sim_sections('/content/'+pdb_code1.lower()+'/smooth_'+pdb_code1.lower()+'_writhes.dat',\n",
        "                          '/content/'+pdb_code2.lower()+'/smooth_'+pdb_code2.lower()+'_writhes.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O6-_1jsg5ohS"
      },
      "outputs": [],
      "source": [
        "#@title Calculate Writhe Profile of Full Backbone (Noisy and Slow)\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "curveFile='/content/'+pdb_code.lower()+'/'+pdb_code.lower()+'.xyz'\n",
        "calculate_writhe(curveFile)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HUnCmsoU6lot"
      },
      "outputs": [],
      "source": [
        "#@title Plot Full Writhe Profile\n",
        "#@title Plot Writhe Profile\n",
        "pdb_code = \"\" #@param {type:\"string\"}\n",
        "colors = px.colors.sequential.dense\n",
        "DI = np.genfromtxt('/content/'+pdb_code.lower()+'/'+pdb_code.lower()+'_writhes.dat')[:len(np.genfromtxt('/content/'+pdb_code.lower()+'/'+pdb_code.lower()+'.xyz'))-4]\n",
        "x1 = DI[:,0]\n",
        "x2 = DI[:,1]\n",
        "x = x2-x1\n",
        "y = DI[:,2]\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=x,y=y,mode='lines',name=pdb_code.upper(),\n",
        "                         marker=dict(color='black',size=10),\n",
        "                         line=dict(width=5)))\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=0.75*1000)\n",
        "fig.update_layout(\n",
        "    font_family=\"Tenorite\",\n",
        "    font_color=\"black\",\n",
        "    title_font_family=\"Tenorite\",\n",
        "    title_font_color=\"black\",\n",
        "    legend_title_font_color=\"black\",\n",
        "    xaxis_title=\"Subsection Length\",\n",
        "    yaxis_title=\"Writhe\",\n",
        "    font=dict(size=16)\n",
        ")\n",
        "fig.update_layout(template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5_WNzHOMiWUN"
      },
      "outputs": [],
      "source": [
        "#@title Process your own PDB file\n",
        "#@markdown First, using the file explorer on the left, upload your own PDB file. Then enter its location below and press the play button.\n",
        "#@markdown This will retrieve the backbone curve and secondary structure prediction using PSIPRED<sup>[1]</sup>.\n",
        "pdb_file_loc = \"\" #@param {type:\"string\"}\n",
        "chain_id = \"\" #@param {type:\"string\"}\n",
        "fr = open(pdb_file_loc, 'r')\n",
        "fw = open('/content/'+os.path.basename(pdb_file_loc)[:-4]+'CA.dat','w+')\n",
        "for record in fr:\n",
        "    if(re.search(r'^ATOM\\s+\\d+\\s+CA\\s+', record)):\n",
        "        fw.write(record)\n",
        "fr.close()\n",
        "fw.close()\n",
        "parser = PDBParser(PERMISSIVE=False,QUIET=False)\n",
        "structure = parser.get_structure(os.path.basename(pdb_file_loc)[:-4],'/content/'+os.path.basename(pdb_file_loc)[:-4]+'CA.dat')\n",
        "XYZ=[]\n",
        "for model in structure:\n",
        "    chains = model.get_chains()\n",
        "    ids = []\n",
        "    for chain in chains:\n",
        "        ids.append(chain.get_id())\n",
        "    chain = model[ids[0]]\n",
        "    for residue in chain:\n",
        "        for atom in residue:\n",
        "            XYZ.append(atom.get_coord())\n",
        "for i in range(len(XYZ)):\n",
        "    XYZ[i] = XYZ[i].tolist()\n",
        "    for j in range(3):\n",
        "        XYZ[i][j] = float(XYZ[i][j])\n",
        "write_curve_to_file(XYZ,'/content/'+os.path.basename(pdb_file_loc)[:-4]+'.xyz')\n",
        "os.remove('/content/'+os.path.basename(pdb_file_loc)[:-4]+'CA.dat')\n",
        "pdb_to_fasta(pdb_file_loc,chain_id)\n",
        "single_submit(pdb_file_loc[:-4]+'.fasta', \"foo@bar.com\", pdb_file_loc)\n",
        "write_curve_to_file(skmt_upload(pdb_file_loc,chain_id),pdb_file_loc[:-4]+'_smooth.xyz')\n",
        "#shutil.rmtree(pdb_file_loc[:-4]+'.fasta output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gPt5Lxb5uAMe"
      },
      "outputs": [],
      "source": [
        "#@title Calculate Writhe Profile of your Smoothed Backbone\n",
        "pdb_file_loc = \"\" #@param {type:\"string\"}\n",
        "curveFile=pdb_file_loc[:-4]+'_smooth.xyz'\n",
        "calculate_writhe(curveFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBLEMa2yuKLj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plot Writhe Profile\n",
        "colors = px.colors.sequential.dense\n",
        "pdb_file_loc = \"\" #@param {type:\"string\"}\n",
        "highlight_helical_subsections = False #@param {type:\"boolean\"}\n",
        "highlight_roadie_subsections = False #@param {type:\"boolean\"}\n",
        "DI = np.genfromtxt(pdb_file_loc[:-4]+'_smooth_writhes.dat')[:len(np.genfromtxt(pdb_file_loc[:-4]+'_smooth.xyz'))-4]\n",
        "if highlight_helical_subsections:\n",
        "    try:\n",
        "        res1 = find_helical_sections(pdb_file_loc[:-4]+'_smooth_writhes.dat')\n",
        "        colspace = np.linspace(0,10,len(res1)+2)[1:-1]\n",
        "    except:\n",
        "        print('No helical subsections')\n",
        "        highlight_helical_subsections=False\n",
        "if highlight_roadie_subsections:\n",
        "    try:\n",
        "        res2 = find_roadie_sections(pdb_file_loc[:-4]+'_smooth_writhes.dat')\n",
        "        colspace = np.linspace(0,10,len(res2)+2)[1:-1]\n",
        "    except:\n",
        "        print('No roadie subsections')\n",
        "        highlight_roadie_subsections=False\n",
        "x1 = DI[:,0]\n",
        "x2 = DI[:,1]\n",
        "x = x2-x1+1\n",
        "y = DI[:,2]\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=x,y=y,mode='lines',name=os.path.basename(pdb_file_loc)[:-4],\n",
        "                         marker=dict(color='black',size=10),\n",
        "                         line=dict(width=5)))\n",
        "if highlight_helical_subsections:\n",
        "    for i in range(len(res1)):\n",
        "        stindex = np.where(x == res1[i][0])[0][0]\n",
        "        endex = np.where(x==res1[i][1])[0][0]\n",
        "        fig.add_trace(go.Scatter(x=x[stindex:endex],y=y[stindex:endex],\n",
        "                                  mode='lines',\n",
        "                                  name='Helical Subsection '+str(i+1),\n",
        "                                  showlegend=True,\n",
        "                                  marker=dict(color=colors[int(colspace[i])],\n",
        "                                              size=10),\n",
        "                                  line=dict(width=7.5)\n",
        "                                  )\n",
        "        )\n",
        "if highlight_roadie_subsections:\n",
        "    for i in range(len(res2)):\n",
        "        stindex = np.where(x == res2[i][0]+4)[0][0]\n",
        "        endex = np.where(x==res2[i][1])[0][0]\n",
        "        fig.add_trace(go.Scatter(x=x[stindex:endex],y=y[stindex:endex],\n",
        "                                  mode='lines',\n",
        "                                  name='Roadie Subsection '+str(i+1),\n",
        "                                  showlegend=True,\n",
        "                                  marker=dict(color=colors[int(colspace[i])],\n",
        "                                              size=10),\n",
        "                                  line=dict(width=7.5)\n",
        "                                  )\n",
        "        )\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=0.75*1000)\n",
        "fig.update_layout(\n",
        "    font_family=\"Tenorite\",\n",
        "    font_color=\"black\",\n",
        "    title_font_family=\"Tenorite\",\n",
        "    title_font_color=\"black\",\n",
        "    legend_title_font_color=\"black\",\n",
        "    xaxis_title=\"Subsection Length\",\n",
        "    yaxis_title=\"Writhe\",\n",
        "    font=dict(size=16)\n",
        ")\n",
        "fig.update_layout(template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "thV9nJhMup1f"
      },
      "outputs": [],
      "source": [
        "#@title View Smoothed Molecule\n",
        "pdb_file_loc = \"\" #@param {type:\"string\"}\n",
        "highlight_helical_subsections = False #@param {type:\"boolean\"}\n",
        "highlight_roadie_subsections = False #@param {type:\"boolean\"}\n",
        "if highlight_helical_subsections:\n",
        "  DI = np.genfromtxt(pdb_file_loc[:-4]+'_smooth_writhes.dat')[:len(np.genfromtxt(pdb_file_loc[:-4]+'_smooth.xyz'))-4]\n",
        "  res = find_helical_sections(pdb_file_loc[:-4]+'_smooth_writhes.dat')\n",
        "  view_molecule_helical('/content/'+os.path.basename(pdb_file_loc)[:-4]+'_smooth.xyz',DI,res)\n",
        "if highlight_roadie_subsections:\n",
        "  DI = np.genfromtxt(pdb_file_loc[:-4]+'_smooth_writhes.dat')[:len(np.genfromtxt(pdb_file_loc[:-4]+'_smooth.xyz'))-4]\n",
        "  res = find_roadie_sections(pdb_file_loc[:-4]+'_smooth_writhes.dat')\n",
        "  view_molecule_helical('/content/'+os.path.basename(pdb_file_loc)[:-4]+'_smooth.xyz',DI,res)\n",
        "else:\n",
        "  view_molecule('/content/smooth_'+os.path.basename(pdb_file_loc)[:-4]+'.xyz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<sup>[1]</sup>**The PSIPRED Server** Buchan DWA, Jones DT (2019). The PSIPRED Protein Analysis Workbench: 20 years on. Nucleic Acids Research. https://doi.org/10.1093/nar/gkz297"
      ],
      "metadata": {
        "id": "CgqQv8Tqllyy"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}